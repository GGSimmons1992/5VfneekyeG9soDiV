{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2c74b81-8cf5-4858-9671-b97989d62211",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(5000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 5 seconds\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from gensim.models import Word2Vec, FastText\n",
    "from gensim.models.phrases import Phrases, Phraser\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, \"../src/\")\n",
    "import util as util\n",
    "\n",
    "%autosave 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca76ca37-4ebe-454b-b94e-9ff009147962",
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = [\"full-stack software engineer\", \"engineering manager\",\"aspiring human resources\"]\n",
    "maxVisibleCandidates = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8eea0bf7-1344-412f-a953-b5c6ca07c255",
   "metadata": {},
   "outputs": [],
   "source": [
    "originalCandidates = pd.read_csv('../data/raw/potential-talents-AspiringHumanResources-SeekingHumanResources.csv')\n",
    "originalCandidates.loc[originalCandidates['connection'] == '500+ ','connection'] = '500'\n",
    "originalCandidates['connection'] = originalCandidates['connection'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d5a9e4d-6d4a-4ae7-bb60-bcc2e8131edb",
   "metadata": {},
   "source": [
    "# Spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "efacd631-8198-4496-abca-ef0cd3a66873",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor query in queries:\\n    print(query)\\n    candidates = originalCandidates.copy()\\n    candidates[\\'fit\\'] = candidates[\\'job_title\\'].apply(lambda x: util.scoreSpacySimilary(query,x))\\n    candidates = candidates.sort_values(by=[\\'fit\\',\\'connection\\'],ascending=False)\\n    candidates = candidates.reset_index(drop=True)\\n    for i in range(maxVisibleCandidates):\\n        print(f\"{i}: {candidates.loc[i,\\'job_title\\']} {candidates.loc[i,\\'fit\\']}\")\\n    print(\\'---\\')\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "for query in queries:\n",
    "    print(query)\n",
    "    candidates = originalCandidates.copy()\n",
    "    candidates['fit'] = candidates['job_title'].apply(lambda x: util.scoreSpacySimilary(query,x))\n",
    "    candidates = candidates.sort_values(by=['fit','connection'],ascending=False)\n",
    "    candidates = candidates.reset_index(drop=True)\n",
    "    for i in range(maxVisibleCandidates):\n",
    "        print(f\"{i}: {candidates.loc[i,'job_title']} {candidates.loc[i,'fit']}\")\n",
    "    print('---')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e374f37-ecb2-42ca-bdca-e758dcbabe1b",
   "metadata": {},
   "source": [
    "# Bag Of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bcf93c2f-0040-47ba-9814-3731c1944096",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nvectorObject = CountVectorizer()\\n\\nutil.scoreViaVectorMethod(originalCandidates,vectorObject,queries,maxVisibleCandidates)\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "vectorObject = CountVectorizer()\n",
    "\n",
    "util.scoreViaVectorMethod(originalCandidates,vectorObject,queries,maxVisibleCandidates)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "654bcce9-7d2e-4071-aa47-128342565755",
   "metadata": {},
   "source": [
    "# TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "303b32d5-2675-4aee-adf7-5388931581e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nutil.scoreViaVectorMethod(originalCandidates,TfidfVectorizer(),queries,maxVisibleCandidates)\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "util.scoreViaVectorMethod(originalCandidates,TfidfVectorizer(),queries,maxVisibleCandidates)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c36f8036-183e-4fb9-89db-fb787c1404bd",
   "metadata": {},
   "source": [
    "# Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c41d620c-5f03-4776-80d7-a55ef7634ff3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ncandidates = originalCandidates.copy()\\njob_titles = candidates[['job_title']].values.ravel()\\njobSentences = [title.split() for title in job_titles]\\nquerySentences = [title.split() for title in queries]\\nallSentences = jobSentences + querySentences\\nmodel = Word2Vec(sentences=allSentences, window=5, min_count=1, workers=4)\\n\\njobVectors = np.array([(model.wv[jobSentence]).mean(axis=0) for jobSentence in jobSentences])\\n\\nfor query in queries:\\n    print(query)\\n    query_vector = (model.wv[query.split()]).mean(axis=0).reshape(1,-1)\\n    \\n    candidates['fit'] = cosine_similarity(jobVectors,query_vector)\\n    util.sortAndDisplay(candidates,maxVisibleCandidates)\\n\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "candidates = originalCandidates.copy()\n",
    "job_titles = candidates[['job_title']].values.ravel()\n",
    "jobSentences = [title.split() for title in job_titles]\n",
    "querySentences = [title.split() for title in queries]\n",
    "allSentences = jobSentences + querySentences\n",
    "model = Word2Vec(sentences=allSentences, window=5, min_count=1, workers=4)\n",
    "\n",
    "jobVectors = np.array([(model.wv[jobSentence]).mean(axis=0) for jobSentence in jobSentences])\n",
    "\n",
    "for query in queries:\n",
    "    print(query)\n",
    "    query_vector = (model.wv[query.split()]).mean(axis=0).reshape(1,-1)\n",
    "    \n",
    "    candidates['fit'] = cosine_similarity(jobVectors,query_vector)\n",
    "    util.sortAndDisplay(candidates,maxVisibleCandidates)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e54013-3989-4036-a2cb-67cf6ed8f371",
   "metadata": {},
   "source": [
    "# Glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0551d493-37ea-42d7-8377-f884359df075",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ncandidates = originalCandidates.copy()\\njob_titles = candidates[[\\'job_title\\']].values.ravel()\\nallPhrases = list(job_titles) + queries\\nallWords = set([word.lower() for word in (\" \".join(allPhrases)).split()])\\ntokenizer = Tokenizer()\\ntokenizer.fit_on_texts(allWords)\\nembedding_dim = 50\\nembedding_matrix_vocab = util.embedding_for_vocab(\\n    \\'../glove.6B.50d.txt\\', tokenizer.word_index,\\n    embedding_dim)\\nfor query in queries:\\n    print(query)\\n    candidates = originalCandidates.copy()\\n    candidates[\\'fit\\'] = candidates[\\'job_title\\'].apply(lambda x: util.retrieveGloveSimilarityScore(x,query,embedding_matrix_vocab,tokenizer))\\n    util.sortAndDisplay(candidates,maxVisibleCandidates)\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "candidates = originalCandidates.copy()\n",
    "job_titles = candidates[['job_title']].values.ravel()\n",
    "allPhrases = list(job_titles) + queries\n",
    "allWords = set([word.lower() for word in (\" \".join(allPhrases)).split()])\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(allWords)\n",
    "embedding_dim = 50\n",
    "embedding_matrix_vocab = util.embedding_for_vocab(\n",
    "    '../glove.6B.50d.txt', tokenizer.word_index,\n",
    "    embedding_dim)\n",
    "for query in queries:\n",
    "    print(query)\n",
    "    candidates = originalCandidates.copy()\n",
    "    candidates['fit'] = candidates['job_title'].apply(lambda x: util.retrieveGloveSimilarityScore(x,query,embedding_matrix_vocab,tokenizer))\n",
    "    util.sortAndDisplay(candidates,maxVisibleCandidates)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c6c442-951e-4ed7-8666-5959b390bc20",
   "metadata": {},
   "source": [
    "# FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c16d68c-adaf-44cf-9909-51526a63dc60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full-stack software engineer\n",
      "0: Seeking employment opportunities within Customer Service or Patient Care 0.4767184853553772\n",
      "1: Aspiring Human Resources Management student seeking an internship 0.4364079236984253\n",
      "2: Aspiring Human Resources Management student seeking an internship 0.4364079236984253\n",
      "3: Retired Army National Guard Recruiter, office manager,  seeking a position in Human Resources. 0.42836588621139526\n",
      "4: Human Resources professional for the world leader in GIS software 0.4236786961555481\n",
      "5: Director of Human Resources North America, Groupe Beneteau 0.4156807065010071\n",
      "6: Admissions Representative at Community medical center long beach 0.41557878255844116\n",
      "7: Seeking Human Resources Opportunities 0.39169004559516907\n",
      "8: Seeking Human Resources Opportunities 0.39169004559516907\n",
      "9: Bachelor of Science in Biology from Victoria University of Wellington 0.39092615246772766\n",
      "10: Experienced Retail Manager and aspiring Human Resources Professional 0.3867005705833435\n",
      "11: Seeking Human  Resources Opportunities. Open to travel and relocation. 0.38171443343162537\n",
      "12: Student at Humber College and Aspiring Human Resources Generalist 0.3719143867492676\n",
      "13: Student at Humber College and Aspiring Human Resources Generalist 0.3719143867492676\n",
      "14: Student at Humber College and Aspiring Human Resources Generalist 0.3719143867492676\n",
      "---\n",
      "engineering manager\n",
      "0: Retired Army National Guard Recruiter, office manager,  seeking a position in Human Resources. 0.4771054983139038\n",
      "1: Experienced Retail Manager and aspiring Human Resources Professional 0.46806231141090393\n",
      "2: Business Management Major and Aspiring Human Resources Manager 0.45718371868133545\n",
      "3: Aspiring Human Resources Manager, seeking internship in Human Resources. 0.4512860178947449\n",
      "4: Aspiring Human Resources Management student seeking an internship 0.4474871754646301\n",
      "5: Aspiring Human Resources Management student seeking an internship 0.4474871754646301\n",
      "6: Seeking employment opportunities within Customer Service or Patient Care 0.39281535148620605\n",
      "7: Admissions Representative at Community medical center long beach 0.35752636194229126\n",
      "8: Human Resources, Staffing and Recruiting Professional 0.33872783184051514\n",
      "9: Liberal Arts Major. Aspiring Human Resources Analyst. 0.3185919523239136\n",
      "10: Aspiring Human Resources Professional 0.31500428915023804\n",
      "11: Aspiring Human Resources Professional 0.31500428915023804\n",
      "12: Aspiring Human Resources Professional 0.31500428915023804\n",
      "13: Aspiring Human Resources Professional 0.31500428915023804\n",
      "14: Aspiring Human Resources Professional 0.31500428915023804\n",
      "---\n",
      "aspiring human resources\n",
      "0: Aspiring Human Resources Professional 0.744329571723938\n",
      "1: Aspiring Human Resources Professional 0.744329571723938\n",
      "2: Aspiring Human Resources Professional 0.744329571723938\n",
      "3: Aspiring Human Resources Professional 0.744329571723938\n",
      "4: Aspiring Human Resources Professional 0.744329571723938\n",
      "5: Aspiring Human Resources Professional 0.744329571723938\n",
      "6: Aspiring Human Resources Professional 0.744329571723938\n",
      "7: Aspiring Human Resources Manager, seeking internship in Human Resources. 0.7085297107696533\n",
      "8: Aspiring Human Resources Specialist 0.6968268752098083\n",
      "9: Aspiring Human Resources Specialist 0.6968268752098083\n",
      "10: Aspiring Human Resources Specialist 0.6968268752098083\n",
      "11: Aspiring Human Resources Specialist 0.6968268752098083\n",
      "12: Aspiring Human Resources Specialist 0.6968268752098083\n",
      "13: Aspiring Human Resources Management student seeking an internship 0.6580882668495178\n",
      "14: Aspiring Human Resources Management student seeking an internship 0.6580882668495178\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "candidates = originalCandidates.copy()\n",
    "job_titles = candidates[['job_title']].values.ravel()\n",
    "allPhrases = list(job_titles) + queries\n",
    "jobSentences = [title.split() for title in list(job_titles)]\n",
    "sentences = [title.split() for title in allPhrases]\n",
    "phrases = Phrases(sentences, min_count = 30, progress_per = 10000)\n",
    "sentences = phrases[sentences]\n",
    "model = FastText(window = 5, min_count = 5, workers = 4, min_n = 1, max_n = 4)\n",
    "model.build_vocab(sentences)\n",
    "jobVectors = np.array([(model.wv[jobSentence]).mean(axis=0) for jobSentence in jobSentences])\n",
    "\n",
    "for query in queries:\n",
    "    print(query)\n",
    "    query_vector = (model.wv[query.split()]).mean(axis=0).reshape(1,-1)\n",
    "    \n",
    "    candidates['fit'] = cosine_similarity(jobVectors,query_vector)\n",
    "    util.sortAndDisplay(candidates,maxVisibleCandidates)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c136e48a-111e-4df9-a8c5-b23d22c113a5",
   "metadata": {},
   "source": [
    "# Bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6a3d2a-3732-404f-8e16-7cfc439995de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "adecd53e-0386-41c1-8caf-a2ea1c370c70",
   "metadata": {},
   "source": [
    "# Sbert"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c64d027-df8d-4484-ac73-35b300ab86c5",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "887aa39d-2f70-424d-984b-a1a51cb0d6bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
